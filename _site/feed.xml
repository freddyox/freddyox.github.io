<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.2.1">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2018-05-06T12:56:48-04:00</updated><id>/</id><title type="html">Projects and Research Interests</title><subtitle>Projects and Research Interests</subtitle><entry><title type="html">Word Search</title><link href="/blog/word-search/" rel="alternate" type="text/html" title="Word Search" /><published>2018-01-04T00:00:00-05:00</published><updated>2018-01-04T00:00:00-05:00</updated><id>/blog/word-search</id><content type="html" xml:base="/blog/word-search/"></content><summary type="html">An interactive word search game</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="" /></entry><entry><title type="html">Mona Lisa from Triangles?</title><link href="/blog/mona-lisa/" rel="alternate" type="text/html" title="Mona Lisa from Triangles?" /><published>2017-08-28T00:00:00-04:00</published><updated>2017-08-28T00:00:00-04:00</updated><id>/blog/mona-lisa</id><content type="html" xml:base="/blog/mona-lisa/">&lt;p&gt;&lt;i&gt;Disclaimer&lt;/i&gt;: I got the idea from &lt;a href=&quot;https://rogerjohansson.blog/2008/12/07/genetic-programming-evolution-of-mona-lisa/&quot;&gt;this blogging site&lt;/a&gt;,
but the implementation/algorithms are mine. The blogger calls this a &quot;genetic algorithm&quot; but it's just a simple hill-climbing
method defined by some &amp;chi;&lt;sup&gt;2&lt;/sup&gt;, a common technique in my work.
Additionally, I used the bare-bones &lt;a href=&quot;https://www.sfml-dev.org/&quot;&gt;SFML library&lt;/a&gt; which required
significant image processing and filtering methods to be developed; this has been done on purpose for my own education!
While the results are pleasing, the algorithm is not practical (at least mine). An animation of the algorithm is located at the bottom.
&lt;/p&gt;

&lt;h2 id=&quot;concept&quot;&gt;Concept&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;image right&quot;&gt;&lt;img src=&quot;/images/mona_lisa/original.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The goal is to mimick or replicate an input image using polygons, or triangles in this case.
The main components of the algorithm are as follows:
&lt;ol&gt;
&lt;li&gt;Have an input image that we wish to copy, &lt;i&gt;e.g.&lt;/i&gt; the Mona Lisa&lt;/li&gt;
&lt;li&gt;Randomly generate an initial set of &lt;i&gt;N&lt;/i&gt; triangles, typically 50-500&lt;/li&gt;
&lt;li&gt;Define an appropriate &amp;chi;&lt;sup&gt;2&lt;/sup&gt; function, often referred to as a loss or fitness function, which
    will allow us to quantify the difference between the triangle image and the input image &lt;/li&gt; 
&lt;li&gt;Apply a &lt;q&gt;mutation&lt;/q&gt;, &lt;i&gt;i.e.&lt;/i&gt; randomly tweak a characteristic of the triangle like a vertex
    coordinate or an RGBA value&lt;/li&gt;
&lt;li&gt;Calculate the &amp;chi;&lt;sup&gt;2&lt;/sup&gt; between the mutated image and the input; if the function determines
    that the mutatation is more similar to the input then accept the change. Otherwise, discard it, and apply another mutation&lt;/li&gt;
&lt;li&gt;Repeat until the loss function does not change significantly.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;With low-level C++ libraries, the difficulty here is to develop the appropriate routines to handle the image processing.
For example, &lt;i&gt;N&lt;/i&gt; triangles are randomly generated in which there is significant overlap; therefore, RGBA values
are being added together in a complicated manner. While more sophisticated methods can be developed,
I chose to draw the triangles on a canvas in order to visually see
the result of a mutation (for example, a coordinate mutation can affect a significant fraction of the RGBA of the mutation image).
In order to process the mutated image, the code takes a screen shot of the mutation and then breaks it apart into
a vector such that the RGBA components may be easily compared to the input image.&lt;/p&gt;

&lt;p&gt;Let's define the word &lt;i&gt;mutation&lt;/i&gt; clearly. A mutation only applies to the triangle image, and in general
represents some random tweaking of triangle attributes. In this case, one triangle has three vertices and each
vertex has two coordinates and an RGBA value; this is 6 parameters per vertex for a grand total of 18 per triangle! Therefore,
the number of parameters to tweak making up the triangle image goes like &lt;i&gt;N*18&lt;/i&gt; where &lt;i&gt;N&lt;/i&gt; is the number
of triangles. The difficulty is to decide how much to randomly tweak a parameter. If the mutation is too small then
it is easy for the code to get stuck in a local minima, but if it is too large then the mutation rate is compromised.
I used a flat random number generator for all parameters, and kept the coordinate mutations loose while keeping tight
mutations on the color components. There is a lot of room for improvement in these choices, I think.&lt;/p&gt;

The &amp;chi;&lt;sup&gt;2&lt;/sup&gt; function is defined to be the square difference of R,G,B,A components for all pixels between the input
and mutated image, and is normalized by &lt;i&gt;(N pixels)*4*256*256&lt;/i&gt; such that
the loss function &lt;i&gt;L = 1-&lt;/i&gt;&amp;chi;&lt;sup&gt;2&lt;/sup&gt; yields a number less than or equal to 1 where 1 is a perfect match.
This can be computationally slow if you have large images as the code is simply brute force. The heart of the
algorithm depends on this function as the newly mutated image gets compared to the input image via the loss function. If
the loss function is calculated to be better than the previous triangle image, then the mutation is kept; otherwise,
the code will discard the mutation and randomly try again.
The mutation rate, &lt;i&gt;i.e.&lt;/i&gt; the number of accepted mutations over the total number of mutation attempts,
at first is acceptable but then quickly becomes linear resulting in a slow algorithm (still fun though).&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/mona_lisa/mutation_rate.png&quot; alt=&quot;&quot; height=&quot;99%&quot; width=&quot;99%&quot; /&gt;
  &lt;figcaption&gt;Fig. 1 - The normalized loss (L=1-&amp;chi;&lt;sup&gt;2&lt;/sup&gt;) as a function of mutation number.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt; &lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;p&gt;In order to make convergence faster, I gridded up the input image and found the average color of each grid.
I generated 300 triangles with randomly placed vertices and calculated the vertex coordinate average which dictates
the triangle's initial color based off the average grid colors.
I let the code do 1e6 mutation attempts (as opposed to successes)
in which only 23,721 mutations were accepted, which is a mutation rate of 2.4% if I assume linearity.
The best loss is L=0.9966, and it remained this way for quite some time as the slope is so small (see Fig. 1 at large mutations).
The quality of the image does converge, meaning that more computational time is most likely futile. The results
of this project may be seen by the animation in Fig. 2.
The results may be greatly improved by considering polygons (I've seen ellipses too), but the number of parameters
to tweak is now &lt;i&gt;N*V*6&lt;/i&gt; where &lt;i&gt;V&lt;/i&gt; is the number of vertices..
Also, the use of triangles leads to sharp edges in the output image. This can be smoothed out by developing
filtering techniques, &lt;i&gt;e.g.&lt;/i&gt; a Gaussian blur, and I spent a great deal of time learning how to apply
convolution matrices or image masks (google kernel image processing). 
&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/mona_lisa/mona_lisa_rs.gif&quot; alt=&quot;&quot; height=&quot;30%&quot; width=&quot;30%&quot; /&gt;
  &lt;figcaption&gt;Fig. 2 - An animation of mutation attempts and successes. The page might need to be reloaded
  as I currently do not know how to control/pause the .gif.&lt;/figcaption&gt;
&lt;/figure&gt;</content><summary type="html">A hill climbing method to mimick an input image with randomly generated triangles</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="/images/mona_lisa/mona_lisa.jpg" /></entry><entry><title type="html">Plinko</title><link href="/blog/plinko/" rel="alternate" type="text/html" title="Plinko" /><published>2017-08-27T00:00:00-04:00</published><updated>2017-08-27T00:00:00-04:00</updated><id>/blog/plinko</id><content type="html" xml:base="/blog/plinko/">&lt;h2 id=&quot;objective&quot;&gt;Objective&lt;/h2&gt;
&lt;p&gt;Plinko is a popular game perhaps due to “The Price is Right”. A contestant
gets up to 5 plinko chips (piece of plastic that resembles a hockey puck),
each of which are worth up to $10,000.
The idea then is quite simple; the contestant chooses an initial starting point at the top
of the board and releases the plinko chip, and hopes to win some money
($0, $100, $500, $1k, $10k are possible outcomes). The fun part, though, is watching
the chip traverse the plinko board. The board is an array of metal pegs,
each row is offset by half a lattice spacing, which forces the chip to change its
trajectory many times. The bin where the chip ends up dictates
how much money is awarded, if any at all, to the contestant. On the show, there are
9 bins and the center bin is the $10k prize. Naively, the odds of obtaining
the big bucks are 1/9, but the odds are initial-condition dependent as we will see.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/plinko/plinko_summary_scaled.png&quot; alt=&quot;&quot; height=&quot;99%&quot; width=&quot;99%&quot; /&gt;
  &lt;figcaption&gt;Fig. 1 - Results of the plinko simulation for a varying number of attempts.
  From top to bottom and left to right, the number of simulations
  is 10&lt;sup&gt;2&lt;/sup&gt;, 10&lt;sup&gt;3&lt;/sup&gt;, 10&lt;sup&gt;4&lt;/sup&gt;, 10&lt;sup&gt;5&lt;/sup&gt;,
  and 10&lt;sup&gt;6&lt;/sup&gt;. Note that the initial condition is the same.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;/p&gt;
&lt;h2 id=&quot;simulation&quot;&gt;Simulation&lt;/h2&gt;
&lt;p&gt;The simulation setup is summarized by Fig. 1 in which an NxN lattice is generated
where every other row is horizontally offset by half a lattice spacing. The initial
condition is chosen to be roughly the center as it provides the most interesting
results visually. I initially wanted to do the simulation using billiard ball
collisions and forces (momentum and energy conservation, etc.), but
the situation can be dramatically simplified. When a plinko chip encounters a peg,
let's randomly choose a direction to go, left or right, and  propagate this strategy
down the plinko board. If we repeat the game many times then
we've achieved a simple Monte Carlo simulation. The situation
is actually identical to a one-dimensional random walk (or drunken walk)
which follows a binomial distribution. After many steps,
the binomial may be well approximated by a Gaussian, and
the most probable ending spot for the 1D drunkard is exactly where he started.
Therefore, a naive expectation for the plinko simulation is the chip end-bin
distribution to look like a Gaussian with a mean corresponding to the starting
position and a standard deviation that depends on the lattice size or granularity
of the board.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image left&quot;&gt;&lt;img src=&quot;/images/plinko/ssplinko_nsim_350.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;
The algorithm to generate a visualization of the plinko simulation uses techniques that I commonly use in my work.
We need an easy way to track the path of a chip; therefore, I need coordinates of all decisions. This can
be efficiently done by first creating a map, or table, that relates any given peg to its closest neighbors.
A simple radius clustering search may be used, but we are only interested in the two closest pegs
&lt;i&gt;below&lt;/i&gt; as they dictate where the chip will move next. Lastly, the path of the chip needs to be traced, where
a path consists of many line segments that connect the left/right decisions throughout the board.
Since we are dealing with coordinates in a lattice,
I Gaussian-smeared the line segment coordinates to avoid an overlap of many paths in addition to
giving the path a more fluid feel. This is what gives the horizontal spread in the observed paths, and explains
why a path occasionally crosses a peg.&lt;/p&gt;

&lt;p&gt;The end-bin plinko chip distribution is plotted within Fig. 2 where the bin size corresponds
to the lattice spacing in the simulation. The left (right) panel throws 100 (10&lt;sup&gt;4&lt;/sup&gt;)
plinko chips, and essentially a perfect Gaussian distribution is observed if the number
of events is large as expected.
Therefore, the ideal starting-position to get the 10k per chip
on &quot;The Price is Right&quot; is the bin that aligns with the 10k bin. Note that I actually did
watch a guy hit the 10k bin 3 out of 5 times which is highly unlikely, see 
&lt;a href=&quot;https://www.youtube.com/watch?v=naUppHrHJpI&quot;&gt;this youtube video&lt;/a&gt;, and won
$31.5k!&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&quot;/images/plinko/plinko_results.png&quot; alt=&quot;&quot; height=&quot;99%&quot; width=&quot;99%&quot; /&gt;
  &lt;figcaption&gt;Fig. 2 - The plinko chip distribution for two simulations
  of 100 (left) and 10&lt;sup&gt;4&lt;/sup&gt; (right) attempts. Dividing each bin by the total number
  of events yields a probability distribution.&lt;/figcaption&gt;
&lt;/figure&gt;</content><summary type="html">Simulating the famous plinko game</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="" /></entry><entry><title type="html">Koch Snowflake</title><link href="/blog/koch-snowflake/" rel="alternate" type="text/html" title="Koch Snowflake" /><published>2017-05-10T00:00:00-04:00</published><updated>2017-05-10T00:00:00-04:00</updated><id>/blog/koch-snowflake</id><content type="html" xml:base="/blog/koch-snowflake/">&lt;figure&gt;
&lt;img src=&quot;/images/koch_snowflake/flake_thumbnail.png&quot; alt=&quot;&quot; title=&quot;Koch&quot; width=&quot;99%&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;span class=&quot;image left&quot;&gt;&lt;img src=&quot;/images/koch_snowflake/idea.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;
I worked on this project immediately after the tree fractal. Admittedly, the geometry is more
difficult but the fractal generation concept is the same; find a base operation, and apply
it iteratively. The fractal begins by defining an
equilateral triangle, and let's refer to this as iteration 0. Iteration 1 is
formed by taking each line segment making up the base triangle, splitting it into thirds,
removing the center segment, and then building a smaller equilateral (with one side missing)
with two additional line segments. The result is a star.
Therefore, the base operation of the fractal consists of accepting one line segment
and returning four in the proper orientation. Repeat the iteration process until satisfied, but
practically only the first 6 iterations or so make noticeable changes without magnification.
An animation of my Koch snowflake may be seen by Fig. 2. The area of the fractal
quickly converges, but the perimeter tends towards infinity; see Fig. 3 for my results.
Note that the number of line segments to consider grows rapidly: &lt;i&gt;3*4&lt;sup&gt;n&lt;/sup&gt;&lt;/i&gt;
where &lt;i&gt;n&lt;/i&gt; is the iteration number. Therefore, the animation displays the first
10 iterations resulting in a fractal with &lt;i&gt;3.14*10&lt;sup&gt;6&lt;/sup&gt;&lt;/i&gt; line segments.
&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/koch_snowflake/asymm.gif&quot; alt=&quot;&quot; title=&quot;Koch snowflake animation&quot; width=&quot;80%&quot; /&gt;
&lt;figcaption&gt;Fig. 2 - The first 10 iterations of a variation of the Koch snowflake. While
the area of the fractal converges rapidly, the perimeter tends towards infinity, see
Fig. 3.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/koch_snowflake/results.png&quot; alt=&quot;&quot; title=&quot;Koch snowflake animation&quot; width=&quot;99%&quot; /&gt;
&lt;figcaption&gt;Fig. 3 - The area and perimeter of a true Koch snowflake (not the the one seen in the
animation). The area converges quickly while the perimeter diverges towards infinity.
The convergence of the fractal area is suppose to be 8/5 times the original
area of the base triangle, which is observed in the plot.&lt;/figcaption&gt;
&lt;/figure&gt;</content><summary type="html">A variation of the Koch snowflake</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="" /></entry><entry><title type="html">Tree Fractal</title><link href="/blog/tree-fractal/" rel="alternate" type="text/html" title="Tree Fractal" /><published>2016-05-08T00:00:00-04:00</published><updated>2016-05-08T00:00:00-04:00</updated><id>/blog/tree-fractal</id><content type="html" xml:base="/blog/tree-fractal/">&lt;figure&gt;
  &lt;img src=&quot;/images/tree_fractal/fractal_tree_multi.jpg&quot; alt=&quot;&quot; height=&quot;99%&quot; width=&quot;99%&quot; /&gt;
  &lt;figcaption&gt;Fig. 1 - The fractal tree generated with branch angles of 23 (left panel)
  and 60 (right) degrees.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;generating-and-animating-the-fractal&quot;&gt;Generating and Animating the Fractal&lt;/h2&gt;
&lt;p&gt;There are many ways to generate a simple tree fractal. A quick google search gives many variations
and patterns, symmetric and asymmetric, as even small changes to the initial length and/or
angle gives interesting results. I will only describe &lt;i&gt;my&lt;/i&gt; fractal as I am not a
fractal expert; the goal for me was to generate a symmetric tree fractal,
and then to tweak parameters and make an animation.&lt;/p&gt;

&lt;p&gt;The fractal starts with a tree trunk of length &lt;i&gt;l&lt;/i&gt;, and think of
the top of the trunk as a node where we will connect branches. Fractals
are iterative objects, so in this case the trunk is referred to as level zero.
Each time we increment the level, 2 branches will be connected to each node
of the previous level resulting in 2&lt;sup&gt;&lt;i&gt;n&lt;/i&gt;&lt;/sup&gt; new branches where &lt;i&gt;n&lt;/i&gt;
represents the level. A branch is just a line defined by two coordinates.
The first level of the fractal, then, generates two branches,
both assigned a length &lt;i&gt;al&lt;/i&gt; where &lt;i&gt;a&lt;/i&gt; is some fraction to be defined by the coder,
with the trunk node as the starting coordinate; the end coordinate depends on the fractal generation
angle. If I choose an angle of say 23 degrees as in Fig. 1, then the first level
branches have end points that are plus/minus 23 degrees with respect to the vertical, or
more generally the directional vector of the trunk (or branch of the previous level).
Level two branches (there are 2&lt;sup&gt;2&lt;/sup&gt;=4)
use level 1 nodes as input where the length is now &lt;i&gt;a&lt;sup&gt;2&lt;/sup&gt;l&lt;/i&gt;, and the end points
are defined &lt;i&gt;relative&lt;/i&gt; to the level 1 branch directional vectors. The process
is iterated to as many levels as one wants, but note that the length of level &lt;i&gt;n&lt;/i&gt;
branches are reduced relative to the trunk by a factor of &lt;i&gt;a&lt;sup&gt;n&lt;/sup&gt;&lt;/i&gt;. For example,
if we choose &lt;i&gt;a&lt;/i&gt;=0.7, then the length of level 7 branches is 0.7&lt;sup&gt;7&lt;/sup&gt;=0.08
or 8% of the trunk's length which quickly becomes difficult to visualize.
Additionally, the tree fractal naturally gives rise to a curling
or rotational effect which yields often unexpected behavior, &lt;i&gt;e.g.&lt;/i&gt; the
right panel of Fig. 1.&lt;/p&gt;

&lt;p&gt;
I used a value of &lt;i&gt;a&lt;/i&gt;=0.65 and &lt;i&gt;n&lt;/i&gt;=15, and incrementally changed the color of branches
as the algorithm progresses to higher branch levels, hence the variations of green
and the red/pink buds. Obviously a great deal of time could be invested tweaking
various parameters and checking the result; the tweaking can be intensified by
considering asymmetric parameters for left/right branch generation at any particular node.
The algorithm can easily be extended to scan over a range of branch generation angles,
say 0 to 360 degrees, and the output can be stringed together to create a .gif using
conventional linux facilities. The results of such a procedure may be seen by Fig. 2,
and if the .gif does not work then see the video on my
&lt;a href=&quot;https://youtu.be/7bijV3FGrBk&quot;&gt;youtube channel&lt;/a&gt;.
Fractal analysis can be performed on the output, but I stopped here. See
&lt;a href=&quot;https://www.youtube.com/watch?v=Ec8Q1q9cbbo&quot;&gt;this video&lt;/a&gt; for
a spectacular demonstration of the variety of tree fractals.
&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/tree_fractal/fractal2.gif&quot; alt=&quot;&quot; title=&quot;Tree fractal animation&quot; width=&quot;99%&quot; /&gt;
&lt;figcaption&gt;Fig. 2 - Scanning over branch generation angles of 0 to 360 degrees in 1 degree
increments, and stitching all the images together to create an animation.&lt;/figcaption&gt;
&lt;/figure&gt;</content><summary type="html">Generation and visualization of a Pythagoras tree</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="" /></entry><entry><title type="html">Collisions</title><link href="/blog/brownian/" rel="alternate" type="text/html" title="Collisions" /><published>2015-07-27T00:00:00-04:00</published><updated>2015-07-27T00:00:00-04:00</updated><id>/blog/brownian</id><content type="html" xml:base="/blog/brownian/">&lt;figure&gt;
&lt;img src=&quot;/images/brownian/brownian.png&quot; alt=&quot;&quot; /&gt;
&lt;figcaption&gt;
Fig. 1 - The double pendulum simulation for two different initial conditions.
&lt;/figcaption&gt;
&lt;/figure&gt;</content><summary type="html">Simulating many collisions (close to brownian motion)</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="" /></entry><entry><title type="html">Double Pendulum</title><link href="/blog/double-pendulum/" rel="alternate" type="text/html" title="Double Pendulum" /><published>2015-07-27T00:00:00-04:00</published><updated>2015-07-27T00:00:00-04:00</updated><id>/blog/double-pendulum</id><content type="html" xml:base="/blog/double-pendulum/">&lt;figure&gt;
&lt;img src=&quot;/images/double_pend/double_pend_v3.png&quot; alt=&quot;&quot; /&gt;
&lt;figcaption&gt;
Fig. 1 - The double pendulum simulation for two different initial conditions.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;
The double pendulum is a canonical classical mechanics problem to introduce
the concept of chaos; the description will therefore be brief.
First, find the equations of motion using forces or
the Lagrangian method; this describes the angles and angular velocities of the two masses.
No attempt will be made to derive the EOM as I've done it many times and do not have
an interest in latexing classical mechanics.
The masses and pendula arm-lengths can be different which gives rise to interesting behavior.
The initial angles are chosen with a flat random number generator.
The equations of motion need to be approximated, and in this case I used the Runge-Kutta method
otherwise known as RK4. The last piece of the project is the visualization, so we need
a method to update the angles and angular velocities using a time variable. I added a simple
tracer routine to follow the position of the masses, and the alpha component
decays as a function of time. Additionally, it is a simple extension to change
the tracer color as a function of time or coordinates.
A small video displaying
the simulation output may be seen on my
&lt;a href=&quot;https://youtu.be/CuhPbDQs3eY&quot;&gt;youtube channel&lt;/a&gt;. Note that with very little
effort, the double pendulum simulation may be used as a spirograph generator.
&lt;/p&gt;</content><summary type="html">Simulating the double pendulum using RK4.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="" /></entry></feed>
